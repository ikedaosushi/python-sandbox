{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "\n",
    "import os, sys, re, datetime, time\n",
    "from pathlib import Path\n",
    "\n",
    "pj_dir = Path(os.getcwd()).parents[1]\n",
    "data_dir = pj_dir/'data'\n",
    "img_dir = pj_dir/'images'\n",
    "src_dir = pj_dir/'src'\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "plt.style.use(\"bmh\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (16, 4)\n",
    "plt.rcParams[\"font.family\"] = \"IPAexGothic\"\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpholiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfall = pd.read_pickle(data_dir/'kaizen_slack/all_messages.pickle')\n",
    "df_channel = pd.read_pickle(data_dir/'kaizen_slack/channels.pickle')\n",
    "df_member = pd.read_pickle(data_dir/'kaizen_slack/members.pickle')\n",
    "df = pd.read_pickle(data_dir/'kaizen_slack/messages.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_message_types = ['channel_join', 'channel_leave', 'channel_topic', 'channel_archive', 'channel_purpose', 'sh_room_created', 'channel_name', 'pinned_item', 'reminder_add', 'app_conversation_join']\n",
    "df = df[~df['subtype'].isin(not_message_types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_trimed'] = df['text'].str.replace(r'<\\S+>', '').str.replace(r':\\S+:', '').str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summarizer.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec(window=1, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376096, 53)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = ' '.join(df['text_trimed'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df, n):\n",
    "    for idx in range(0, df.shape[0], n):\n",
    "        yield df.iloc[idx:idx + n, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_words(doc):\n",
    "    mecab = MeCab.Tagger(\"-Ochasen -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "    lines = mecab.parse(doc).splitlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        chunks = line.split('\\t')\n",
    "        if len(chunks) > 3 and (chunks[3].startswith('動詞') or chunks[3].startswith('形容詞') or (chunks[3].startswith('名詞') and not chunks[3].startswith('名詞-数'))):\n",
    "            words.append(chunks[0])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    tmp_words = split_into_words(row['text_trimed'])\n",
    "    words.append(tmp_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 105685 words, keeping 10547 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 187020 words, keeping 14261 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 291905 words, keeping 18029 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 399301 words, keeping 20699 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 526440 words, keeping 22339 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 624872 words, keeping 24889 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 761931 words, keeping 28136 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 889971 words, keeping 31681 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 986882 words, keeping 33912 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 1138409 words, keeping 36821 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 1269464 words, keeping 40639 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 1394919 words, keeping 42415 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1521858 words, keeping 43818 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1650078 words, keeping 45106 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1820416 words, keeping 47474 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1987080 words, keeping 50975 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 2141842 words, keeping 52045 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 2301928 words, keeping 53485 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 2396419 words, keeping 55862 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 2547535 words, keeping 57514 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 2697583 words, keeping 58887 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 2832828 words, keeping 59879 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 2961514 words, keeping 60798 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 3084030 words, keeping 61587 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 3207216 words, keeping 63070 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 3349900 words, keeping 64494 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 3495587 words, keeping 66418 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 3613014 words, keeping 67365 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 3727769 words, keeping 68135 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 3878146 words, keeping 68850 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 4024400 words, keeping 70658 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 4139663 words, keeping 72268 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 4250728 words, keeping 73508 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 4347710 words, keeping 75812 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #350000, processed 4443280 words, keeping 77085 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #360000, processed 4557060 words, keeping 78567 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #370000, processed 4656783 words, keeping 80405 word types\n",
      "INFO:gensim.models.word2vec:collected 81492 word types from a corpus of 4700548 raw words and 376096 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=1 retains 81492 unique words (100% of original 81492, drops 0)\n",
      "INFO:gensim.models.word2vec:effective_min_count=1 leaves 4700548 word corpus (100% of original 4700548, drops 0)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 81492 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 37 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 4258428 word corpus (90.6% of prior 4700548)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 81492 words and 100 dimensions: 105939600 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 4 workers on 81492 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 27.53% examples, 1054814 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 51.92% examples, 1117511 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 77.73% examples, 1131616 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 4700548 raw words (4258361 effective words) took 3.7s, 1155635 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 32.45% examples, 1285612 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 55.19% examples, 1200724 words/s, in_qsize 6, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 84.08% examples, 1234187 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 4700548 raw words (4258015 effective words) took 3.5s, 1219374 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 29.68% examples, 1175097 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 54.86% examples, 1189083 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 80.82% examples, 1177002 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 4700548 raw words (4258262 effective words) took 3.8s, 1115044 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 30.58% examples, 1203900 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 58.11% examples, 1263957 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 84.60% examples, 1237061 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 4700548 raw words (4257950 effective words) took 3.5s, 1204481 effective words/s\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 31.97% examples, 1260523 words/s, in_qsize 6, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 59.65% examples, 1299866 words/s, in_qsize 8, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 86.85% examples, 1261674 words/s, in_qsize 7, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 4700548 raw words (4258262 effective words) took 3.4s, 1238950 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 23502740 raw words (21290850 effective words) took 18.0s, 1180079 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(words, size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saving Word2Vec object under /Users/yutaro_ikeda/.ghq/github.com/ikedaosushi/python-sandbox/data/kaizen_slack/w2v.model, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "INFO:gensim.utils:saved /Users/yutaro_ikeda/.ghq/github.com/ikedaosushi/python-sandbox/data/kaizen_slack/w2v.model\n"
     ]
    }
   ],
   "source": [
    "model.save(str(data_dir/'kaizen_slack/w2v.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n",
      "/Users/yutaro_ikeda/.pyenv/versions/3.6.5/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('yasu', 0.9081540107727051),\n",
       " ('jimbo', 0.8986175656318665),\n",
       " ('kogure', 0.8938308954238892),\n",
       " ('andy', 0.8859750032424927),\n",
       " ('sakai', 0.8749969005584717),\n",
       " ('masao', 0.8628397583961487),\n",
       " ('banin', 0.8570758104324341),\n",
       " ('nishiya', 0.855423092842102),\n",
       " ('shino', 0.8463077545166016),\n",
       " ('榊原', 0.8343085050582886)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('keiji')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutaro_ikeda/.pyenv/versions/3.6.5/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('takus', 0.8530447483062744),\n",
       " ('watabe', 0.8480912446975708),\n",
       " ('inu', 0.8280203938484192),\n",
       " ('sue', 0.8273420333862305),\n",
       " ('keiji', 0.8154975175857544),\n",
       " ('もひ', 0.8071255683898926),\n",
       " ('andy', 0.8007967472076416),\n",
       " ('yu-ki', 0.8006150722503662),\n",
       " ('peco', 0.7980176210403442),\n",
       " ('ikeda', 0.7975234985351562)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('kawabe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yutaro_ikeda/.pyenv/versions/3.6.5/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('HIS', 0.8339268565177917),\n",
       " ('鈴森', 0.8333430290222168),\n",
       " ('安江', 0.831693172454834),\n",
       " ('ゼクシィ', 0.8308569192886353),\n",
       " ('Rakuma', 0.8258123397827148),\n",
       " ('渡辺由美子', 0.8252314329147339),\n",
       " ('関口', 0.8242795467376709),\n",
       " ('大和田', 0.8239831328392029),\n",
       " ('ニューバランス', 0.8221687078475952),\n",
       " ('GMOインサイト株式会社', 0.8211828470230103)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"グーグル\"], negative=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
