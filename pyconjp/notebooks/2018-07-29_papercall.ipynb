{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"8a4d7c68509907868913e318cb8d0ae8\"\n",
    "state = \"accepted\"\n",
    "per_page = 1000\n",
    "endpoint = f\"https://www.papercall.io/api/v1/submissions?_token={token}&state={state}&per_page={per_page}\"\n",
    "res = requests.get(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '1次元畳み込みフィルターを利用した音楽データのオートエンコーダ',\n",
       " 'description': '# 概略\\r\\n音楽の楽譜データであるmidiファイルをもとに音楽を自動生成するという試みは、すでにGoogle Magenta にて実施されている。\\r\\nしかし、midiではなく、mp3やma4などの音響データで音楽が配布されたり取得されたりする場合が多い。\\r\\n録音データをmidiに変換する自動採譜の技術もあるが、これも完璧ではない。\\r\\n\\r\\nそこで今回、音響データを符号化し、midiのように扱いやすいデータに変換した上で、\\r\\n音楽自動生成へとつなげていきたいと考えた。\\r\\n\\r\\n# 実装\\r\\n\\r\\nPythonには、データの符号化、つまりオートエンコーダを生成するための機械学習ライブラリが潤沢に用意されていることに加え、\\r\\nPythonでは音響データの一つである.wavファイルを取り扱える関数がネイティブに提供されているため、本テーマを扱うのに最適な言語である。\\r\\npythonにおけるwavデータは以下のように扱える\\r\\n\\r\\nimport wave  \\r\\nwavfile = \\'sample.wav\\'  \\r\\nwr = wave.open(wavfile, \"rb\")  \\r\\norigin = wr.readframes(wr.getnframes())  \\r\\ndata = origin[:44100 * 2 *  180] # 180sec  \\r\\nwr.close()  \\r\\n\\r\\n\\r\\nこのようにして得られた音響データをオートエンコーダにかける。\\r\\n音響データは時系列データの波形データとして得られるのだが、\\r\\nより波形としての特徴を色濃く表現したいと考えたため、\\r\\n一次元の畳込みフィルターを採用したオートエンコーダを考案した。\\r\\n\\r\\n一次元畳み込みフィルターの構築は単純で、Kerasを利用して次のように書くことができる。\\r\\n\\r\\n\\r\\nfrom keras.models import Sequential, load_model  \\r\\nfrom keras.layers import Dense, Flatten, Reshape  \\r\\nfrom keras.layers.noise import GaussianNoise  \\r\\nfrom keras.layers.convolutional import Conv1D, UpSampling1D  \\r\\nfrom keras.layers.pooling import MaxPooling1D  \\r\\n\\r\\nmodel = Sequential()  \\r\\nmodel.add(Conv1D(4, 7, strides=7, padding=\\'same\\', input_shape=(44100, 2), activation=\\'relu\\'))  \\r\\nmodel.add(UpSampling1D(7))   \\r\\nmodel.add(Conv1D(4, 7, padding=\\'same\\', activation=\\'relu\\'))  \\r\\nmodel.add(Conv1D(2, 8, padding=\\'same\\', activation=\\'tanh\\'))  \\r\\n\\r\\n\\r\\nここではPooling層を使わずにstridesを利用して次元削減を実行している。\\r\\n\\r\\n# 解釈\\r\\n\\r\\n上で述べたオートエンコーダは次のようにエンコーダとデコーダに分離される\\r\\n\\r\\n\\r\\nencoder = K.function([model.layers[0].input], [model.layers[0].output])  \\r\\ndecoder = K.function([model.layers[1].input], [model.layers[3].output])  \\r\\n\\r\\n\\r\\nこの時、`encoder`は音響データを機械が音楽を理解しやすい形に変換していることになる。\\r\\nエンコードされたデータから音響データが再現できるのであれば、\\r\\nエンコードされたデータは一種の楽譜のようなものであり、`encoder`は採譜機となる\\r\\nまた、エンコードデータから音響データを再現する`decoder`は音源として解釈することができる。\\r\\n\\r\\n# まとめ\\r\\n\\r\\n- 音響データを種とした音楽自動生成ツールを作りたい\\r\\n- そのためには大きなデータ次元を持つ音響データを扱いやすい形にする必要がある\\r\\n- 今回、音響データのオートエンコーダを一次元畳み込みフィルターを利用して実装した\\r\\n- 音響データをエンコードしたものは機械が解釈できる楽譜であると考えることができる',\n",
       " 'notes': '一次元畳み込みフィルターのアプローチの仕方には様々な種類があるので、現在も最適なものを探して試行中です',\n",
       " 'abstract': '音楽を自動生成したいという目的に対し、最も大きな障壁となるのが音声データのデータ量の多さである。一般的な音楽データは44.1kHzというサンプリング周波数を持っており、ステレオの音楽であれば1秒間に88200のデータ点が存在することになる。今回、この音楽データを効率よく圧縮し、音楽生成へと転用するために、最近時系列データの処理において注目を集めている、一次元畳み込みフィルターを用いた符号化を目指す。実装にはポピュラーな機械学習ライブラリであるKerasを利用した。',\n",
       " 'audience_level': 'All',\n",
       " 'talk_format': 'Talk (30 minutes)'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions[0]['talk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks = [ [\\\n",
    "    s['talk']['title'], s['talk']['description'], s['talk']['audience_level'], \n",
    "    s['talk']['talk_format'], ', '.join(s['tags']) \\\n",
    "    ] for s in submissions\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(talks, columns=['title', 'description', 'audience_level', 'talk_format', 'tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('title').to_clipboard( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "icecream.csv\n",
      "tokyo-weather-2003-2012.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/papercall.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
