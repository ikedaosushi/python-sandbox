{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.14.2\n",
      "pandas 0.23.0\n",
      "sklearn 0.19.1\n",
      "lightgbm 2.2.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "\n",
    "import os, sys, re, datetime, gc\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "for p in [np, pd, sklearn, lgb]:\n",
    "    print (p.__name__, p.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.home()/'.kaggle/competitions/house-prices-advanced-regression-techniques'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir/'train.csv.gz', compression='gzip')\n",
    "test = pd.read_csv(data_dir/'test.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data.select_dtypes(include=['object']))\n",
    "data = pd.concat([data, dummies], axis=1)\n",
    "X = data.drop(['SalePrice'], axis=1).select_dtypes(exclude=['object']).fillna(0)\n",
    "y = np.log(data['SalePrice'].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(data.select_dtypes(include=['object']))\n",
    "test = pd.concat([test, dummies], axis=1)\n",
    "test = test.select_dtypes(exclude=['object']).fillna(0)\n",
    "test = test[list(X.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid, X_meta_valid, y_train_valid, y_meta_valid = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.5, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error of model 1: 0.0239\n",
      "mean squared error of model 2: 0.0181\n",
      "mean squared error of model 3: 0.0634\n",
      "mean squared error of meta model: 0.0175\n"
     ]
    }
   ],
   "source": [
    "# train base model\n",
    "base_model_1 = LinearRegression()\n",
    "base_model_2 = LGBMRegressor()\n",
    "base_model_3 = KNeighborsRegressor()\n",
    "\n",
    "base_model_1.fit(X_train, y_train)\n",
    "base_model_2.fit(X_train, y_train)\n",
    "base_model_3.fit(X_train, y_train)\n",
    "\n",
    "# base predicts\n",
    "base_pred_1 = base_model_1.predict(X_valid)\n",
    "base_pred_2 = base_model_2.predict(X_valid)\n",
    "base_pred_3 = base_model_3.predict(X_valid)\n",
    "\n",
    "# test predicts for final result \n",
    "valid_pred_1 = base_model_1.predict(X_meta_valid)\n",
    "valid_pred_2 = base_model_2.predict(X_meta_valid)\n",
    "valid_pred_3 = base_model_3.predict(X_meta_valid)\n",
    "\n",
    "print (\"mean squared error of model 1: {:.4f}\".format(mean_squared_error(y_meta_valid, valid_pred_1)) )\n",
    "print (\"mean squared error of model 2: {:.4f}\".format(mean_squared_error(y_meta_valid, valid_pred_2)) )\n",
    "print (\"mean squared error of model 3: {:.4f}\".format(mean_squared_error(y_meta_valid, valid_pred_3)) )\n",
    "\n",
    "# stack base predicts for training meta model\n",
    "stacked_predictions = np.column_stack((base_pred_1, base_pred_2, base_pred_3))\n",
    "\n",
    "# stack test predicts for final result \n",
    "stacked_valid_predictions = np.column_stack((valid_pred_1, valid_pred_2, valid_pred_3))\n",
    "\n",
    "# train meta model \n",
    "meta_model = LinearRegression()\n",
    "meta_model.fit(stacked_predictions, y_valid)\n",
    "\n",
    "# final result \n",
    "meta_valid_pred = meta_model.predict(stacked_valid_predictions)\n",
    "print (\"mean squared error of meta model: {:.4f}\".format(mean_squared_error(y_meta_valid, meta_valid_pred)) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
